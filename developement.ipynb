{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, csv, re, time\n",
    "from datetime import datetime\n",
    "import ujson as json\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "\n",
    "def get_page(url):\n",
    "    '''Get the page content\n",
    "\n",
    "    Args:\n",
    "        url (str): url to scrape\n",
    "\n",
    "    Returns:\n",
    "        response (obj): object of web content\n",
    "    '''\n",
    "    time.sleep(5)\n",
    "    headers = {'user-agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:73.0) Gecko/20100101 Firefox/73.0'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response\n",
    "    else:\n",
    "        print(f'Something went wrong when scraping {url}')\n",
    "\n",
    "def copy_content(response):\n",
    "    '''Copy the web content in local disk\n",
    "\n",
    "    Parameters\n",
    "        response (obj): object of web content\n",
    "    '''\n",
    "    with open('check.html', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "        \n",
    "def save_data(news_title, news_contents):\n",
    "    '''Save news_title and news_contents in data file\n",
    "    \n",
    "    Parameters\n",
    "        news_title (str): news title\n",
    "        news_content (str): news content\n",
    "    '''\n",
    "    file_name = 'train.csv'\n",
    "    file = os.path.join('data', file_name)\n",
    "    if os.path.exists(file): \n",
    "        mode = 'a'\n",
    "    else:\n",
    "        mode = 'w'\n",
    "    # write in the data\n",
    "    with open(file, mode=mode, newline='') as csv_file:\n",
    "        fieldnames = ['Title', 'Contents']\n",
    "        csv_writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        if mode == 'w': csv_writer.writeheader()\n",
    "        data_dict = dict(zip(fieldnames, [news_title, news_contents]))\n",
    "        csv_writer.writerow(data_dict)\n",
    "\n",
    "    print(f'{news_title} written in successfully')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScrapeLiberty():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, data=None):\n",
    "        self.url_base = 'https://news.ltn.com.tw/ajax/breakingnews/'\n",
    "        self.categories = ['entertainment', 'politics', 'sports', 'society']\n",
    "        self.data = data\n",
    "        self.news_titles = self.data[:, 2] if self.data else []\n",
    "    \n",
    "    def scrape(self):\n",
    "        data = []\n",
    "        for category in self.categories:\n",
    "            index = 1\n",
    "            \n",
    "            url = f'{self.url_base}/{category}/{index}'\n",
    "            news_list = get_page(url)\n",
    "            news_list = json.loads(news_list.text)['data']\n",
    "            \n",
    "            for news in news_list:\n",
    "                url = news['url']\n",
    "                datum = self.process_page(url, category)\n",
    "                if datum:\n",
    "                    data.append(datum)\n",
    "            print(data)\n",
    "    \n",
    "    def process_page(self, url, category):\n",
    "        response = get_page(url)\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        article = self.get_article(soup, category)\n",
    "\n",
    "        news_title = self.get_title(article)\n",
    "        if news_title in self.news_titles:\n",
    "            return None\n",
    "\n",
    "        date = self.get_date(article, category)\n",
    "        news_content = self.get_content(article)\n",
    "        image_path = self.get_image(news['photo_S'])\n",
    "\n",
    "        return [date, title, content, image_path, category]\n",
    "    \n",
    "    def get_article(self, soup, category):\n",
    "        if categroy in ['entertainment']:\n",
    "            return soup.find('div', class_=\"content\")\n",
    "        else:\n",
    "            return soup.find(itemprop=\"articleBody\")\n",
    "\n",
    "    def get_date(self, article, category):\n",
    "        if categroy in ['entertainment', 'sports']:\n",
    "            pattern = '\\d{4}\\/\\d{2}\\/\\d{2}'\n",
    "            date = re.search(pattern, article.text).group()\n",
    "            date = datetime.strptime(date, '%Y/%m/%d').date()\n",
    "        else:\n",
    "            pattern = '\\d{4}-\\d{2}-\\d{2}'\n",
    "            date = re.search(pattern, article.text).group()\n",
    "            date = datetime.strptime(date, '%Y-%m-%d').date()\n",
    "        return date\n",
    "\n",
    "\n",
    "    def get_title(self, article):\n",
    "        return article.h1.text\n",
    "\n",
    "    def get_content(self, article):\n",
    "        if categroy in ['entertainment']:\n",
    "            news_content_list = article.find_all('p', class_='')\n",
    "            content = ''.join([content.text for content in news_content_list if not content.span])\n",
    "        else:\n",
    "            news_content_list = article.find('div', class_='text boxTitle boxText').find_all('p', class_='', recursive=False)\n",
    "            content = ''.join([content.text for content in news_content_list])\n",
    "        return content\n",
    "    \n",
    "    def get_image(self, url):\n",
    "        image_name = url.split('/')[-1]\n",
    "        image_path = os.path.join('data', 'pictures', 'liberty', image_name)\n",
    "        image = get_page(url)\n",
    "        with open(os.path.join(os.getcwd(), image_path), 'wb') as f:\n",
    "            for chunk in image:\n",
    "                f.write(chunk)\n",
    "        return image_path\n",
    "        \n",
    "# return news_title, news_contents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
